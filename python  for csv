'''from io import StringIOimport urllib.requestimport csvdata=urllib.request.urlopen('http://pythonscraping.com/files/MontyPythonAlbums.csv')data=data.read().decode('ascii', 'ignore')datafile=StringIO(data)csvreader=csv.reader(datafile)file=open("C:\\Users\\abc\\Desktop\\deep.txt","w+")#file.write()#file.close()for i in csvreader:    print(i)    file.write("i")file.close()   '''#------------------------------------------- I am a line of demarcation'''import urllib.request,re,datetime,random,csvfrom bs4 import BeautifulSouprandom.seed(datetime.datetime.now)csvfile=open('C:/Users/abc/Desktop/test.csv','wt',newline='',             encoding='utf-8')writer=csv.writer(csvfile)def store(title,content):    csvrow=[]    csvrow.append(title)#add row    csvrow.append(content)#add row    writer.writerow(csvrow)def get_link(acticle_url):    html=urllib.request.urlopen('http://en.wikipedia.org' + acticle_url)    soup=BeautifulSoup(html,'html.parser')    title=soup.h1.get_text()    content=soup.find('div',{'id':'mw-content-text'}).find('p').get_text()    store(title,content)    return soup.find('div',{'id':'bodyContent'}).findAll('a',href=re.compile("^(/wiki/)(.)*$"))link=get_link('')try:    while len(link)>0:        newActicle=link[random.randint(0,len(link)-1)].attrs['href']        link=get_link(newActicle)        print(link)finally:    csvfile.close()'''#-----------------------------------------I am a line of demarcation#coding:utf-8import csvfile=open('C:/Users/abc/Desktop/testforcsv.csv','w')writer=csv.writer(file)writer.writerow(['a','b','c'])data=[(1,2,3),(4,5,6)]writer.writerows(data)file.close()file=open('C:/Users/abc/Desktop/data.csv','r')reader=csv.reader(file)for line in reader:    print(line)file.close()#-----------------------------------I am a line of demarcation
